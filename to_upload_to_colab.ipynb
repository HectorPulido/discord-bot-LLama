{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHqOJISPKQ38",
    "outputId": "91523472-2d62-4691-de35-339c873bccdb"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/HectorPulido/discord-bot-LLama.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-4vj4756n8Z",
    "outputId": "2d74e8d9-b683-42ee-d2e8-bffddfe8ff55"
   },
   "outputs": [],
   "source": [
    "!cd discord-bot-LLama && git pull origin main\n",
    "!echo \"TOKEN_DISCORD='YOURDISCORDTOKENHERE'\\nMODEL_NAME='ggml-mpt-7b-chat.bin'\" > discord-bot-LLama/.env\n",
    "!ls discord-bot-LLama -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r discord-bot-LLama/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd discord-bot-LLama && python main.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
